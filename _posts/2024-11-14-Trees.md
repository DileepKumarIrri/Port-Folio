# Decision Tree Classifier for Play Tennis Dataset

This project implements a Decision Tree Classifier to predict whether a game of tennis will be played based on weather conditions. The classifier uses the **ID3 (Iterative Dichotomiser 3)** algorithm to select the best attributes by calculating **Information Gain**.

## Dataset

The dataset contains 14 examples with the following features:

| Day  | Outlook  | Temperature | Humidity | Wind   | PlayTennis |
|------|----------|-------------|----------|--------|------------|
| D1   | Sunny    | Hot         | High     | Weak   | No         |
| D2   | Sunny    | Hot         | High     | Strong | No         |
| D3   | Overcast | Hot         | High     | Weak   | Yes        |
| D4   | Rain     | Mild        | High     | Weak   | Yes        |
| D5   | Rain     | Cool        | Normal   | Weak   | Yes        |
| D6   | Rain     | Cool        | Normal   | Strong | No         |
| D7   | Overcast | Cool        | Normal   | Strong | Yes        |
| D8   | Sunny    | Mild        | High     | Weak   | No         |
| D9   | Sunny    | Cool        | Normal   | Weak   | Yes        |
| D10  | Rain     | Mild        | Normal   | Weak   | Yes        |
| D11  | Sunny    | Mild        | Normal   | Strong | Yes        |
| D12  | Overcast | Mild        | High     | Strong | Yes        |
| D13  | Overcast | Hot         | Normal   | Weak   | Yes        |
| D14  | Rain     | Mild        | High     | Strong | No         |

### Target Variable:
- **PlayTennis**: Indicates whether tennis is played (`Yes` or `No`).

## Steps Implemented

1. **Entropy Calculation**: 
   - Calculated the entropy of the entire dataset using the formula:
$\[
     H(S) = - \sum_{i=1}^{c} p_i \log_2(p_i)
\]
$
2. **Information Gain**:
   - Computed Information Gain for each feature (`Outlook`, `Temperature`, `Humidity`, `Wind`) using the formula:
$\[
     IG(S, A) = H(S) - \sum_{v \in \text{Values}(A)} \frac{|S_v|}{|S|} \times H(S_v)
\]
$
3. **Building the Decision Tree**:
   - Selected the feature with the highest Information Gain as the root node.
   - Recursively split the dataset based on the feature values and repeated the process until all nodes were pure or no further splits were possible.

### Sample Results

- **Root Node**: `Outlook`
- **Subtrees**:
  - If `Outlook = Sunny`: Further splits based on `Humidity`.
  - If `Outlook = Overcast`: Always `Yes`.
  - If `Outlook = Rain`: Further splits based on `Wind`.

## How to Run the Project

1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/decision-tree-classifier.git
   cd decision-tree-classifier
